For Linear kernel
c= 1.1 
eps = 0.00001 

number of Support vectors with a>0 == 478 ( I have printed alphas in the code 
and have only included some of the values that I printed. )
0    [0.40849718]
1    [0.09712035]
3    [1.00755236]
4    [0.85903146]
5    [0.06694182]
6    [0.03543076]
7    [0.79040298]
8    [0.6259211]
9    [0.05208877]
10    [0.23682205]
.
.
.
799    [0.34372029]
801    [0.65963558]
802    [0.43781819]
803    [0.02248078]
805    [0.28171261]
806    [0.7665087]
807    [0.42071685]
808    [0.77445355]
810    [0.56773464]
812    [0.78671861]
814    [0.17195302]
816    [0.29258747]
818    [0.42340069]
819    [1.1]
820    [0.50871227]
822    [0.53424382]
823    [0.00567825]
value of w is
[ 3.77173281  0.81487083  0.15919871 -3.49662683  1.18471403 -0.22444898
 -0.90432202  4.1614439  -1.55280476]
accuracy for training  76.2135922330097 %
accuracy for testing  83.00970873786407 %

I tried with C = 1 as well  and eps = 0.00001
 number of Support vectors with a>0  == 480
0    [0.40849718]
1    [0.09712035]
3    [1.]
4    [0.8525655]
5    [0.06590869]
6    [0.03567034]
7    [0.79045738]
8    [0.62595282]
9    [0.05229597]
.
.
.
803    [0.00573596]
805    [0.29673548]
806    [0.76958691]
807    [0.43387933]
808    [0.77056238]
810    [0.58988823]
812    [0.75866572]
814    [0.16753716]
816    [0.30452509]
818    [0.43033835]
819    [1.]
820    [0.41643317]
822    [0.52661663]
value of w is
[ 3.76936391  0.8931228   0.14273189 -3.4612742   1.10151852 -0.2429081
 -0.93284645  4.1171065  -1.5179197 ]
accuracy for training  76.45631067961165 %
accuracy for testing  82.52427184466019 %


_____________________________________________________________________________________
_____________________________________________________________________________________

For Quadratic kernel
c = 10 , 2,3,4,5
value of accuracy was the same  
eps = 0.0001 
For  quadratic kernel
number of Sv == 468
0    [0.32292479]
1    [0.18761143]
3    [1.01111385]
4    [0.75128694]
5    [0.07648198]
6    [0.09309065]
7    [0.60111442]
8    [0.35305524]
9    [0.06980988]
10    [0.26519085]
.
.
805    [0.23473224]
806    [0.70569365]
807    [0.32315012]
808    [0.8089483]
810    [0.5053499]
812    [0.78551282]
814    [0.20529473]
818    [0.18129963]
819    [0.80831359]
820    [0.13691465]
822    [0.61544102]
823    [0.02014256]

 number of Support vectors with a>0  = 468
value of w is
[ 1.57384912 -1.21700426 -1.09995916 -1.75587149 -0.47174531  0.44002254
 -0.63981093  1.5201076   1.20657853  0.43636463  0.6516109   0.49835583
  0.73395156  2.00660834 -0.34419606  0.05912685 -0.43174334  0.61611403
  0.82216033  1.80318801 -0.7622359  -0.61684199  0.0628742   1.16431998
  1.99734337 -0.52788155 -1.37808773 -1.86520951  1.3291297   0.88144917
  1.28470918  1.65902297 -0.27130651  2.23134298  1.52004132 -1.42311304
 -1.19167826]
accuracy for training  79.36893203883496 %
accuracy for testing  84.95145631067962 %


c = 1
value of accuracy was the same  
eps = 0.0000001
For  quadratic kernel
value of aplha grater than zero
0    [0.32292479]
1    [0.18761143]
3    [1.]
4    [0.74309517]
5    [0.07446605]
6    [0.09302948]
7    [0.601355]
8    [0.35330403]
9    [0.07036203]
10    [0.26398461]
.
.
807    [0.31994812]
808    [0.80238114]
810    [0.50568158]
812    [0.77433144]
814    [0.20517652]
818    [0.18607631]
819    [0.80004229]
820    [0.15817232]
822    [0.58921806]
823    [0.02199805]
number of Support vectors with a>0 == 462
value of w is
[ 1.59941827 -1.1197905  -1.06060756 -1.81949271 -0.45777529  0.34459527
 -0.61965356  1.53872573  1.16810649  0.46793409  0.63545484  0.49639998
  0.7450856   1.93366974 -0.33900049  0.03839355 -0.40836044  0.60885594
  0.75677362  1.82677397 -0.79012687 -0.6009007   0.12077937  1.13703805
  2.05438682 -0.578813   -1.3453359  -1.79131104  1.25845297  0.86521793
  1.17712744  1.66833565 -0.24975561  2.18453566  1.52187521 -1.40697438
 -1.13752351]
accuracy for training  79.24757281553399 %
accuracy for testing  84.46601941747574 %


_____________________________________________________________________________________
_____________________________________________________________________________________
c = 5 
eps =0.0000001 
spread = 0.5
For  gaussian kernel
value of aplha grater than zero
0    [0.5]
1    [0.15417133]
2    [0.09064027]
3    [1.07449431]
4    [0.7470995]
5    [0.18630296]
6    [0.13052399]
7    [0.88716261]
8    [0.48258046]
9    [0.129672]
.
.
803    [0.99908736]
806    [0.83877903]
807    [0.43768212]
808    [0.98929618]
810    [0.56925971]
812    [1.14795542]
814    [0.23385079]
818    [0.70603969]
819    [0.67981451]
822    [0.73542921]
823    [0.07336908]
number of Support vectors with a>0== 483
accuracy for training  82.8883495145631 %
accuracy for testing  87.37864077669903 %
c =1 
eps =0.0000001 
spread = 0.5
For  gaussian kernel
value of aplha grater than zero
0    [0.5]
1    [0.15417133]
2    [0.09064027]
3    [1.]
4    [0.69551615]
5    [0.1674746]
6    [0.12674232]
.
.
803    [0.96649682]
806    [0.85812428]
807    [0.4168074]
808    [1.]
810    [0.55827058]
812    [1.]
814    [0.26354924]
818    [0.62185681]
819    [0.64534824]
822    [0.72090738]
823    [0.11733415]
number of Support vectors with a>0 == 493
accuracy for training  82.52427184466019 %
accuracy for testing  85.92233009708738 %



for c = 5
eps = 0.0001
spread = 1
number of Support vectors with a>0  == 492
accuracy for training  76.94174757281553 %
accuracy for testing  83.00970873786407 %





